"""
ğŸ¯ ì±—ë´‡ ì„œë¹„ìŠ¤ - êµ¬í˜„ íŒŒì¼

ì´ íŒŒì¼ì€ ì±—ë´‡ì˜ í•µì‹¬ AI ë¡œì§ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
ì•„ë˜ ì•„í‚¤í…ì²˜ë¥¼ ì°¸ê³ í•˜ì—¬ ì§ì ‘ ì„¤ê³„í•˜ê³  êµ¬í˜„í•˜ì„¸ìš”.

ğŸ“ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. ì´ˆê¸°í™” ë‹¨ê³„ (ChatbotService.__init__)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  - OpenAI Client ìƒì„±                                    â”‚
â”‚  - ChromaDB ì—°ê²° (ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤)                       â”‚
â”‚  - LangChain Memory ì´ˆê¸°í™” (ëŒ€í™” ê¸°ë¡ ê´€ë¦¬)               â”‚
â”‚  - Config íŒŒì¼ ë¡œë“œ                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. RAG íŒŒì´í”„ë¼ì¸ (generate_response ë‚´ë¶€)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  ì‚¬ìš©ì ì§ˆë¬¸ "í•™ì‹ ì¶”ì²œí•´ì¤˜"                              â”‚
â”‚       â†“                                                  â”‚
â”‚  [_create_embedding()]                                   â”‚
â”‚       â†“                                                  â”‚
â”‚  ì§ˆë¬¸ ë²¡í„°: [0.12, -0.34, ..., 0.78]  (3072ì°¨ì›)        â”‚
â”‚       â†“                                                  â”‚
â”‚  [_search_similar()]  â† ChromaDB ê²€ìƒ‰                    â”‚
â”‚       â†“                                                  â”‚
â”‚  ê²€ìƒ‰ ê²°ê³¼: "í•™ì‹ì€ ê³¤ìê°€ê°€ ë§›ìˆì–´" (ìœ ì‚¬ë„: 0.87)        â”‚
â”‚       â†“                                                  â”‚
â”‚  [_build_prompt()]                                       â”‚
â”‚       â†“                                                  â”‚
â”‚  ìµœì¢… í”„ë¡¬í”„íŠ¸ = ì‹œìŠ¤í…œ ì„¤ì • + RAG ì»¨í…ìŠ¤íŠ¸ + ì§ˆë¬¸        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. LLM ì‘ë‹µ ìƒì„±                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  OpenAI GPT-4 API í˜¸ì¶œ                                   â”‚
â”‚       â†“                                                  â”‚
â”‚  "í•™ì‹ì€ ê³¤ìê°€ì—ì„œ ë¨¹ëŠ” ê²Œ ì œì¼ ì¢‹ì•„! ëˆê¹ŒìŠ¤ê°€ ì¸ê¸°ì•¼"    â”‚
â”‚       â†“                                                  â”‚
â”‚  [ì„ íƒ: ì´ë¯¸ì§€ ê²€ìƒ‰]                                      â”‚
â”‚       â†“                                                  â”‚
â”‚  ì‘ë‹µ ë°˜í™˜: {reply: "...", image: "..."}                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. ë©”ëª¨ë¦¬ ì €ì¥ (LangChain Memory)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ëŒ€í™” ê¸°ë¡ì— ì§ˆë¬¸-ì‘ë‹µ ì €ì¥                               â”‚
â”‚  ë‹¤ìŒ ëŒ€í™”ì—ì„œ ì»¨í…ìŠ¤íŠ¸ë¡œ í™œìš©                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


ğŸ’¡ í•µì‹¬ êµ¬í˜„ ê³¼ì œ:

1. **Embedding ìƒì„±**
   - OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
   - ëª¨ë¸: text-embedding-3-large (3072ì°¨ì›)

2. **RAG ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜** â­ ê°€ì¥ ì¤‘ìš”!
   - ChromaDBì—ì„œ ìœ ì‚¬ ë²¡í„° ê²€ìƒ‰
   - ìœ ì‚¬ë„ ê³„ì‚°: similarity = 1 / (1 + distance)
   - threshold ì´ìƒì¸ ë¬¸ì„œë§Œ ì„ íƒ

3. **LLM í”„ë¡¬í”„íŠ¸ ì„¤ê³„**
   - ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ìºë¦­í„° ì„¤ì •)
   - RAG ì»¨í…ìŠ¤íŠ¸ í†µí•©
   - ëŒ€í™” ê¸°ë¡ í¬í•¨

4. **ëŒ€í™” ë©”ëª¨ë¦¬ ê´€ë¦¬**
   - LangChainì˜ ConversationSummaryBufferMemory ì‚¬ìš©
   - ëŒ€í™”ê°€ ê¸¸ì–´ì§€ë©´ ìë™ìœ¼ë¡œ ìš”ì•½


ğŸ“š ì°¸ê³  ë¬¸ì„œ:
- ARCHITECTURE.md: ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ìƒì„¸ ì„¤ëª…
- IMPLEMENTATION_GUIDE.md: ë‹¨ê³„ë³„ êµ¬í˜„ ê°€ì´ë“œ
- README.md: í”„ë¡œì íŠ¸ ê°œìš”


âš ï¸ ì£¼ì˜ì‚¬í•­:
- ì´ íŒŒì¼ì˜ êµ¬ì¡°ëŠ” ê°€ì´ë“œì¼ ë¿ì…ë‹ˆë‹¤
- ììœ ë¡­ê²Œ ì¬ì„¤ê³„í•˜ê³  í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ë‹¨, generate_response() í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ëŠ” ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤
  (app.pyì—ì„œ í˜¸ì¶œí•˜ê¸° ë•Œë¬¸)
"""

import os
from pathlib import Path
from dotenv import load_dotenv
import json

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ
BASE_DIR = Path(__file__).resolve().parent.parent


class ChatbotService:
    """
    ì±—ë´‡ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
    
    ì´ í´ë˜ìŠ¤ëŠ” ì±—ë´‡ì˜ ëª¨ë“  AI ë¡œì§ì„ ìº¡ìŠí™”í•©ë‹ˆë‹¤.
    
    ì£¼ìš” ì±…ì„:
    1. OpenAI API ê´€ë¦¬
    2. ChromaDB ë²¡í„° ê²€ìƒ‰
    3. LangChain ë©”ëª¨ë¦¬ ê´€ë¦¬
    4. ì‘ë‹µ ìƒì„± íŒŒì´í”„ë¼ì¸
    
    ì§ì ‘ êµ¬í˜„í•´ì•¼ í•  ë©”ì„œë“œ:
    - __init__: ëª¨ë“  êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™”
    - _load_config: ì„¤ì • íŒŒì¼ ë¡œë“œ
    - _init_chromadb: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
    - _create_embedding: í…ìŠ¤íŠ¸ â†’ ë²¡í„° ë³€í™˜
    - _search_similar: RAG ê²€ìƒ‰ ìˆ˜í–‰ (í•µì‹¬!)
    - _build_prompt: í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    - generate_response: ìµœì¢… ì‘ë‹µ ìƒì„± (ëª¨ë“  ë¡œì§ í†µí•©)
    """
    
    def __init__(self):
        """
        ì±—ë´‡ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”

        ì´ˆê¸°í™” í•­ëª©:
        1. Config ë¡œë“œ (chatbot_config.json)
        2. OpenAI Client (ì„ë² ë”©ìš©)
        3. ChromaDB (ë²¡í„° ê²€ìƒ‰ìš©)
        4. LangChain ChatOpenAI (ì‘ë‹µ ìƒì„±ìš©)
        5. ë©”ëª¨ë¦¬ ìŠ¤í† ì–´ (ëŒ€í™” ê¸°ë¡ ê´€ë¦¬)
        """
        print("[ChatbotService] ì´ˆê¸°í™” ì¤‘...")

        # 1. Config ë¡œë“œ
        self.config = self._load_config()
        print(f"[ChatbotService] Config ë¡œë“œ ì™„ë£Œ: {self.config.get('name', 'Unknown')}")

        # 2. OpenAI Client ì´ˆê¸°í™” (ì„ë² ë”©ìš©)
        from openai import OpenAI
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        self.client = OpenAI(api_key=api_key)
        print("[ChatbotService] OpenAI Client ì´ˆê¸°í™” ì™„ë£Œ")

        # 3. ChromaDB ì´ˆê¸°í™”
        try:
            self.collection = self._init_chromadb()
            print(f"[ChatbotService] ChromaDB ì—°ê²° ì™„ë£Œ: {self.collection.count()} ë¬¸ì„œ")
        except Exception as e:
            print(f"[ChatbotService] ChromaDB ì—°ê²° ì‹¤íŒ¨: {e}")
            print("[ChatbotService] RAG ê²€ìƒ‰ ì—†ì´ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
            self.collection = None

        # 4. LangChain ChatOpenAI ì´ˆê¸°í™” (ì‘ë‹µ ìƒì„±ìš©)
        from langchain_openai import ChatOpenAI
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.7,
            max_tokens=500,
            api_key=api_key
        )
        print("[ChatbotService] LangChain ChatOpenAI ì´ˆê¸°í™” ì™„ë£Œ")

        # 5. ë©”ëª¨ë¦¬ ìŠ¤í† ì–´ ì´ˆê¸°í™” (ì„¸ì…˜ë³„ ëŒ€í™” ê¸°ë¡)
        # ìµœì‹  LangChain ë°©ì‹: InMemoryChatMessageHistory ì‚¬ìš©
        from langchain_core.chat_history import InMemoryChatMessageHistory
        self.message_store = {}  # session_id -> InMemoryChatMessageHistory
        print("[ChatbotService] ë©”ëª¨ë¦¬ ìŠ¤í† ì–´ ì´ˆê¸°í™” ì™„ë£Œ")

        print("[ChatbotService] ì´ˆê¸°í™” ì™„ë£Œ âœ…\n")
    
    
    def _load_config(self):
        """
        ì„¤ì • íŒŒì¼ ë¡œë“œ

        Returns:
            dict: ì±—ë´‡ ì„¤ì • ì •ë³´
        """
        config_path = BASE_DIR / 'config' / 'chatbot_config.json'
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            return config
        except FileNotFoundError:
            print(f"[WARNING] ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
            # ê¸°ë³¸ ì„¤ì • ë°˜í™˜
            return {
                'name': 'ì±—ë´‡',
                'description': 'ì±—ë´‡ ì„¤ëª…',
                'tags': ['#ì±—ë´‡'],
                'character': {},
                'system_prompt': {
                    'base': 'ë‹¹ì‹ ì€ ì¹œê·¼í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.',
                    'rules': ['ì¹œì ˆí•˜ê²Œ ëŒ€ë‹µí•˜ì„¸ìš”']
                }
            }
        except json.JSONDecodeError as e:
            print(f"[ERROR] JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            raise
    
    
    def _init_chromadb(self):
        """
        ChromaDB ì´ˆê¸°í™” ë° ì»¬ë ‰ì…˜ ë°˜í™˜

        Returns:
            chromadb.Collection: ChromaDB ì»¬ë ‰ì…˜

        Raises:
            Exception: ChromaDB ì—°ê²° ì‹¤íŒ¨ ì‹œ
        """
        import chromadb

        db_path = BASE_DIR / "static" / "data" / "chatbot" / "chardb_embedding"

        # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
        db_path.mkdir(parents=True, exist_ok=True)

        # PersistentClient ìƒì„±
        client = chromadb.PersistentClient(path=str(db_path))

        # ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ìƒì„±)
        try:
            collection = client.get_collection(name="rag_collection")
        except Exception:
            # ì»¬ë ‰ì…˜ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
            print("[ChromaDB] 'rag_collection' ì»¬ë ‰ì…˜ì´ ì—†ì–´ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
            collection = client.create_collection(name="rag_collection")

        return collection
    
    
    def _create_embedding(self, text: str) -> list:
        """
        í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜

        Args:
            text (str): ì„ë² ë”©í•  í…ìŠ¤íŠ¸

        Returns:
            list: 3072ì°¨ì› ë²¡í„° (text-embedding-3-large ëª¨ë¸)
        """
        try:
            response = self.client.embeddings.create(
                input=[text],
                model="text-embedding-3-large"
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"[ERROR] ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    
    def _search_similar(self, query: str, threshold: float = 0.45, top_k: int = 5):
        """
        RAG ê²€ìƒ‰: ìœ ì‚¬í•œ ë¬¸ì„œ ì°¾ê¸° (í•µì‹¬ ë©”ì„œë“œ!)

        Args:
            query (str): ê²€ìƒ‰ ì§ˆì˜
            threshold (float): ìœ ì‚¬ë„ ì„ê³„ê°’ (0.3-0.5 ê¶Œì¥)
            top_k (int): ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜

        Returns:
            tuple: (document, similarity, metadata) ë˜ëŠ” (None, None, None)

        í•µì‹¬ ê°œë…:
        - Distance vs Similarity
          Â· ChromaDBëŠ” "ê±°ë¦¬(distance)"ë¥¼ ë°˜í™˜ (ì‘ì„ìˆ˜ë¡ ìœ ì‚¬)
          Â· ìš°ë¦¬ëŠ” "ìœ ì‚¬ë„(similarity)"ë¡œ ë³€í™˜ (í´ìˆ˜ë¡ ìœ ì‚¬)
          Â· ë³€í™˜ ê³µì‹: similarity = 1 / (1 + distance)
        """
        # ChromaDBê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš°
        if self.collection is None:
            return (None, None, None)

        try:
            # 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_embedding = self._create_embedding(query)

            # 2. ChromaDB ê²€ìƒ‰
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=top_k,
                include=["documents", "distances", "metadatas"]
            )

            # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°
            if not results['documents'][0]:
                print(f"[RAG] ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                return (None, None, None)

            # 3. ìœ ì‚¬ë„ ê³„ì‚° ë° í•„í„°ë§
            best_document = None
            best_similarity = 0
            best_metadata = None

            documents = results['documents'][0]
            distances = results['distances'][0]
            metadatas = results['metadatas'][0]

            for doc, dist, meta in zip(documents, distances, metadatas):
                # ìœ ì‚¬ë„ ê³„ì‚°: similarity = 1 / (1 + distance)
                similarity = 1 / (1 + dist)

                # ë””ë²„ê¹… ì¶œë ¥
                print(f"[RAG] ë¬¸ì„œ: {doc[:50]}... | ê±°ë¦¬: {dist:.4f} | ìœ ì‚¬ë„: {similarity:.4f}")

                # threshold ì´ìƒì´ê³  í˜„ì¬ê¹Œì§€ ìµœê³  ìœ ì‚¬ë„ì¸ ê²½ìš°
                if similarity >= threshold and similarity > best_similarity:
                    best_similarity = similarity
                    best_document = doc
                    best_metadata = meta

            # 4. ìµœì  ë¬¸ì„œ ë°˜í™˜
            if best_document:
                print(f"[RAG] âœ… ì„ íƒëœ ë¬¸ì„œ ìœ ì‚¬ë„: {best_similarity:.4f}")
                return (best_document, best_similarity, best_metadata)
            else:
                print(f"[RAG] âŒ threshold({threshold}) ì´ìƒì¸ ë¬¸ì„œ ì—†ìŒ")
                return (None, None, None)

        except Exception as e:
            print(f"[ERROR] RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return (None, None, None)
    
    
    def _build_prompt(self, user_message: str, context: str = None, username: str = "ì‚¬ìš©ì"):
        """
        LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±

        Args:
            user_message (str): ì‚¬ìš©ì ë©”ì‹œì§€
            context (str): RAG ê²€ìƒ‰ ê²°ê³¼ (ì„ íƒ)
            username (str): ì‚¬ìš©ì ì´ë¦„

        Returns:
            tuple: (system_prompt, user_prompt)
        """
        # 1. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt_config = self.config.get('system_prompt', {})
        base_prompt = system_prompt_config.get('base', 'ë‹¹ì‹ ì€ ì¹œê·¼í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.')
        rules = system_prompt_config.get('rules', [])

        system_prompt = base_prompt
        if rules:
            system_prompt += "\n\n[ëŒ€í™” ê·œì¹™]\n" + "\n".join(f"- {rule}" for rule in rules)

        # 2. ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        user_prompt = ""

        # RAG ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        if context:
            user_prompt += f"[ì°¸ê³  ì •ë³´]\n{context}\n\n"

        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        user_prompt += f"{username}: {user_message}"

        return (system_prompt, user_prompt)
    
    
    def generate_response(self, user_message: str, username: str = "ì‚¬ìš©ì", session_id: str = "default") -> dict:
        """
        ì‚¬ìš©ì ë©”ì‹œì§€ì— ëŒ€í•œ ì±—ë´‡ ì‘ë‹µ ìƒì„± (LangChain ì‚¬ìš©)

        Args:
            user_message (str): ì‚¬ìš©ì ì…ë ¥
            username (str): ì‚¬ìš©ì ì´ë¦„
            session_id (str): ì„¸ì…˜ ID (ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ìš©)

        Returns:
            dict: {
                'reply': str,       # ì±—ë´‡ ì‘ë‹µ í…ìŠ¤íŠ¸
                'image': str|None   # ì´ë¯¸ì§€ ê²½ë¡œ (ì„ íƒ)
            }
        """
        try:
            print(f"\n{'='*60}")
            print(f"[USER] {username} (session: {session_id}): {user_message}")

            # [1ë‹¨ê³„] ì´ˆê¸° ë©”ì‹œì§€ ì²˜ë¦¬
            if user_message.strip().lower() == "init":
                bot_name = self.config.get('name', 'ì±—ë´‡')
                description = self.config.get('description', '')
                init_message = f"ì•ˆë…•! ë‚˜ëŠ” {bot_name}ì´ì•¼."
                if description:
                    init_message += f"\n{description}"

                print(f"[BOT] {init_message}")
                print(f"{'='*60}\n")
                return {
                    'reply': init_message,
                    'image': None
                }

            # [2ë‹¨ê³„] RAG ê²€ìƒ‰ ìˆ˜í–‰
            context, similarity, metadata = self._search_similar(
                query=user_message,
                threshold=0.45,
                top_k=5
            )
            has_context = (context is not None)

            # [3ë‹¨ê³„] í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            system_prompt, user_prompt = self._build_prompt(
                user_message=user_message,
                context=context,
                username=username
            )

            print(f"[RAG] Context found: {has_context}")
            if has_context:
                print(f"[RAG] Similarity: {similarity:.4f}")
                print(f"[RAG] Context preview: {context[:100]}...")

            # [4ë‹¨ê³„] LangChainìœ¼ë¡œ LLM í˜¸ì¶œ
            # ë©”ëª¨ë¦¬ê°€ ìˆëŠ” ê²½ìš°ì™€ ì—†ëŠ” ê²½ìš° ë¶„ê¸°
            from langchain_core.messages import SystemMessage, HumanMessage
            from langchain_core.chat_history import InMemoryChatMessageHistory
            from langchain_core.runnables.history import RunnableWithMessageHistory

            # ì„¸ì…˜ë³„ ë©”ëª¨ë¦¬ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
            if session_id not in self.message_store:
                self.message_store[session_id] = InMemoryChatMessageHistory()

            session_history = self.message_store[session_id]

            # ë©”ì‹œì§€ êµ¬ì„±
            messages = [SystemMessage(content=system_prompt)]

            # ëŒ€í™” ê¸°ë¡ ì¶”ê°€
            messages.extend(session_history.messages)

            # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            messages.append(HumanMessage(content=user_prompt))

            print(f"[LLM] Calling ChatOpenAI... (ëŒ€í™” ê¸°ë¡: {len(session_history.messages)}ê°œ)")

            # LLM í˜¸ì¶œ
            response = self.llm.invoke(messages)
            reply = response.content

            print(f"[BOT] {reply}")
            print(f"{'='*60}\n")

            # [5ë‹¨ê³„] ë©”ëª¨ë¦¬ ì €ì¥
            session_history.add_user_message(user_prompt)
            session_history.add_ai_message(reply)

            # [6ë‹¨ê³„] ì‘ë‹µ ë°˜í™˜
            return {
                'reply': reply,
                'image': None  # ì´ë¯¸ì§€ ê²€ìƒ‰ ë¡œì§ì€ ì¶”í›„ ì¶”ê°€ ê°€ëŠ¥
            }

        except Exception as e:
            import traceback
            print(f"[ERROR] ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            print(traceback.format_exc())
            return {
                'reply': "ì£„ì†¡í•´ìš”, ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                'image': None
            }


# ============================================================================
# ì‹±ê¸€í†¤ íŒ¨í„´
# ============================================================================
# ChatbotService ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì•± ì „ì²´ì—ì„œ ì¬ì‚¬ìš©
# (ë§¤ë²ˆ ìƒˆë¡œ ì´ˆê¸°í™”í•˜ë©´ ë¹„íš¨ìœ¨ì )

_chatbot_service = None

def get_chatbot_service():
    """
    ì±—ë´‡ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì‹±ê¸€í†¤)
    
    ì²« í˜¸ì¶œ ì‹œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±, ì´í›„ ì¬ì‚¬ìš©
    """
    global _chatbot_service
    if _chatbot_service is None:
        _chatbot_service = ChatbotService()
    return _chatbot_service


# ============================================================================
# í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜
# ============================================================================

if __name__ == "__main__":
    """
    ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©
    
    ì‹¤í–‰ ë°©ë²•:
    python services/chatbot_service.py
    """
    print("ì±—ë´‡ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    service = get_chatbot_service()
    
    # ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸
    response = service.generate_response("init", "í…ŒìŠ¤í„°")
    print(f"ì´ˆê¸° ì‘ë‹µ: {response}")
    
    # ì¼ë°˜ ëŒ€í™” í…ŒìŠ¤íŠ¸
    response = service.generate_response("ì•ˆë…•í•˜ì„¸ìš”!", "í…ŒìŠ¤í„°")
    print(f"ì‘ë‹µ: {response}")
